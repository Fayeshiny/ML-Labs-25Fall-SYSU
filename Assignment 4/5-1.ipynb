{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root='~/Datasets/FashionMNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载测试数据\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root='~/Datasets/FashionMNIST',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    '''返回Fashion-MNIST数据集的文本标签'''\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fashion_mnist(images, labels):\n",
    "    '''展示图像和标签'''\n",
    "    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n",
    "    for f, img, lbl in zip(figs, images, labels):\n",
    "        f.imshow(img.view((28, 28)).numpy())\n",
    "        f.set_title(lbl)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist_train.data.shape)\n",
    "'''\n",
    "60000个样本\n",
    "每个样本大小28*28=784\n",
    "'''\n",
    "print(len(mnist_train.targets.unique()))\n",
    "'''\n",
    "10个标签\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxRegression:\n",
    "    def __init__(self):\n",
    "        # 初始化模型参数\n",
    "        self.num_inputs = 784\n",
    "        self.num_outputs = 10\n",
    "\n",
    "        self.W = torch.normal(0, 0.01, size=(self.num_inputs, self.num_outputs), requires_grad=True) #每一个像素点的回归系数\n",
    "        self.b = torch.zeros(self.num_outputs, requires_grad=True) #偏置项\n",
    "\n",
    "    def soft_max(self, X):\n",
    "        \"\"\"   计算softmax\n",
    "        输入: X, 其中size=(n, 10)\n",
    "\n",
    "        对每一行X计算softmax\n",
    "\n",
    "        输出: softmax(X), 其中size=(n, 10)\n",
    "\n",
    "        注意不要用for实现!!!\n",
    "        \"\"\"\n",
    "        return 0\n",
    "\n",
    "    def net(self, X):\n",
    "        \"\"\"定义模型\"\"\"\n",
    "        X = X.view(-1, self.num_inputs)\n",
    "        return self.soft_max(torch.mm(X, self.W) + self.b)\n",
    "\n",
    "    def one_hot_encoder(self, y):\n",
    "        \"\"\"独热编码\"\"\"\n",
    "        a = torch.zeros((len(y), self.num_outputs))\n",
    "        for idx, i in enumerate(y):\n",
    "            a[idx, int(i)] = 1\n",
    "        return a\n",
    "    \n",
    "    def cross_entropy(self, y_hat, y):\n",
    "        y_pred_enc = self.one_hot_encoder(y)\n",
    "        \"\"\"   损失函数\n",
    "        输入: \n",
    "            y_hat, 模型预测概率分布, 其中size=(n, 10)\n",
    "            y, 真实标签, 其中size=(n, 1)\n",
    "        \n",
    "        先对y进行独热编码转为y_pred_enc使其size=(n, 10), 然后计算y_pred_enc与y_hat的交叉熵损失\n",
    "\n",
    "        输出: y_pred_enc与y_hat的 n 个交叉熵损失值\n",
    "\n",
    "        注意不要用for实现!!!\n",
    "        \"\"\"\n",
    "        return 0\n",
    "\n",
    "    def accuracy(self, y_hat, y):\n",
    "        \"\"\"   统计预测正确的数量\n",
    "        输入: \n",
    "            y_hat, 模型预测概率分布, 其中size=(n, 10)\n",
    "            y, 真实标签, 其中size=(n, 1)\n",
    "        \n",
    "        根据概率分布y_hat的标签, 然后和真实标签对比统计预测正确的数量\n",
    "\n",
    "        输出: correct_count 预测正确的数量\n",
    "\n",
    "        注意不要用for实现!!!\n",
    "        \"\"\"\n",
    "        return 0\n",
    "\n",
    "    def evaluate_accuracy(self, net, data_iter):\n",
    "        \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "        correct_count, total_count = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in data_iter:\n",
    "                correct_count += self.accuracy(net(X), y)\n",
    "                total_count += y.numel()\n",
    "        return correct_count / total_count\n",
    "\n",
    "    def train_epoch(self, net, train_iter, loss):\n",
    "        \"\"\"训练模型的一个迭代周期\"\"\"\n",
    "        total_loss, correct_count, total_count = 0, 0, 0\n",
    "        lr = 0.1\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            # 计算损失函数\n",
    "            l = loss(y_hat, y)\n",
    "            # 求梯度\n",
    "            l.mean().backward()\n",
    "            # 更新训练参数\n",
    "            self.W.data -= lr * self.W.grad\n",
    "            self.b.data -= lr * self.b.grad\n",
    "            # 梯度清零\n",
    "            self.W.grad.data.zero_()\n",
    "            self.b.grad.data.zero_()\n",
    "            #计算指标\n",
    "            total_loss += l.sum().item()\n",
    "            correct_count += self.accuracy(y_hat, y)\n",
    "            total_count += y.numel()\n",
    "        # 返回训练损失和训练精度\n",
    "        return total_loss / total_count, correct_count / total_count\n",
    "\n",
    "    def train(self, net, train_iter, test_iter, loss, num_epochs):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "        for epoch in range(num_epochs):\n",
    "            train_metrics = self.train_epoch(net, train_iter, loss)\n",
    "            test_acc = self.evaluate_accuracy(net, test_iter)\n",
    "            train_loss, train_acc = train_metrics\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss}, train_acc: {train_acc}, test_acc: {test_acc}')\n",
    "            assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "            assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "\n",
    "    def predict(self, net, test_iter, n=10):\n",
    "        \"\"\"预测标签\"\"\"\n",
    "        X, y = next(iter(test_iter))\n",
    "        trues = get_fashion_mnist_labels(y)\n",
    "        preds = get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "        titles = [true + '\\n' + pred for true, pred in zip(trues, preds)]# 真实标签与预测标签\n",
    "        show_fashion_mnist(X[0:n], titles[0:n])# 展示图像及其标签[trues, preds]\n",
    "\n",
    "    def run(self,train_iter,test_iter,num_epochs = 1):\n",
    "        self.train(self.net, train_iter, test_iter, self.cross_entropy, num_epochs)\n",
    "        self.predict(self.net, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "SMR = SoftMaxRegression()\n",
    "SMR.run(train_iter,test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
